{
 "metadata": {
  "name": "",
  "signature": "sha256:2aede66729d63261be7d10d9ce2d03c3e572435739f83576af85f8a189b01b4b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "TODO:\n",
      " * With the same train/test split, learn a convolutional auto-encoder over the symbolic chord space\n",
      " * Apply the same network to the output of the chord prediction model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "source": [
      "Convolutional neural networks for chord rec"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "First let's import libraries and set up some convenience functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "!curl https://raw.githubusercontent.com/andreasjansson/chordrec/master/helpers.py > helpers.py 2>/dev/null\n",
      "import helpers\n",
      "from helpers import *\n",
      "from theano.tensor.nnet import conv\n",
      "from theano.tensor.signal import downsample\n",
      "import math\n",
      "\n",
      "import lasagne\n",
      "\n",
      "floatX = theano.config.floatX"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "helpers.S3_BUCKET = os.environ['AWS_S3_BUCKET']\n",
      "helpers.AWS_ACCESS_KEY_ID = os.environ['AWS_ACCESS_KEY_ID']\n",
      "helpers.AWS_SECRET_ACCESS_KEY = os.environ['AWS_SECRET_ACCESS_KEY']"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Data"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Now we download the dataset. I have cached beat-aligned CQTs on S3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = s3_get('chordrec/test_data/beat_aligned_hop4096.pkl', unpickle=True)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "source": [
      "`data` is in the format `[(song1_pitchgram, song1_chords)]`, where the \"pitchgrams\" are 84-element vectors,\n",
      "7 octaves of chromagrams."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'number of tracks:', len(data)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of tracks: 890\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "markdown",
     "source": [
      "The pitchgrams and chords are aligned on the beat level. For example, \"Maniac\" by Michale Sembello has 648 beats analyzed by echonest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maniac = data[375]\n",
      "pitchgram, chords = maniac\n",
      "\n",
      "print 'shape of pitchgrams:', pitchgram.shape\n",
      "print 'shape of chords:', chords.shape"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "shape of pitchgrams: (648, 84)\n",
        "shape of chords: (648,)\n"
       ]
      }
     ],
     "prompt_number": 322
    },
    {
     "cell_type": "markdown",
     "source": [
      "If we plot a subsection (from the 32nd to the 64th beat, C2 to C6) of the pitchgram against the chord labels we can confirm that our pitchgrams and chords are in fact aligned."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "helpers.plot_with_notes_and_chords(pitchgram, chords, min_time=32, max_time=64, min_pitch=12*2, max_pitch=12*6)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEBCAYAAACT92m7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXmYHVWZxt8GktCEHcKONDtiSCAsggsmoCgoKuKCoswg\n4PIMOKg8gtvQCOLgAow4uOCIoiLuAoKgkAUje0jIQthpZI2RJSSEDtJ9549TTZ+uU+eX25Wmk+68\nv+fpp+vet07VqVN166tT9dZ3JGOMMcYYY4wxxhhjjDHGGGOMMcYYY4wxxhhjjDHGDHO6JM2UNEvS\nDEkHrMCy9pb0PwNRqSpamplpX6lx2ytVA2OMGb5MkzQx+rxY0nrF9CGSvlDSVxnWamam2yTdU0xf\nIOmkSLslmv6dpPdEn6dE0zMl7RV9vjuafkTSttHnPUvr3jf6vE80fbmkd2XqXNYej6YnSzqomH6y\nVO5WSfsV08+WtNmSxhXT3SVtjqQ9ium7S9oTkrYspkeWtEclbVNMvwjlFpW0pyVtXExvW9I6JLWp\nmlgrb9+TkrYopl9b0m5Xb9vfV9IekrR9VK/cMsvE2ksl7R+SNiumzyppl0k6qpj+75IWt2dHSVsi\nad1ieu2S9qykDYvpHUpavH23l7RlkkYV0+tF3z8naf3o86HR9B2SJkSf/wTlBNpG0XTcXpL0zWj6\nZ5I+HH1eGE2Xf7PfjqYfk7R1plzcXmXKWtwuCyRtHn1eGk3Hx7TUd1vj34IUzgs9fEXSf0Wf94um\ny+UWRNPl9lwjml4kaYPoc7w95W1oi6bvkbRrMX1lo6GWlpY3Kc8GSn8yPSyRdKGkwxQ248uSzlE4\nvE+WdKVCUPmspMMltUt6lcKh+ipJ5yucrmuzxvJnMcYYM0C0Klwrz5d0kfpe+8yMpteRdL2ksQq9\nja8oXNMeUUxXsYtCb2Q/SadLWnNFKtpUz8EYY8zyWareuyzt7e1Vs7yg3pso+0u6RCEASH1vrrwo\n6dpieo6kToXnFXNVfWOgIekqSf+S9JRCZ3Jz9b1p0i/63XPYD7RXg5a7tSDlu9GStBVou9bUtgdt\na9A2B20z0NYFjbadyrWCluvuL0+j9dF+qLtM0kaDNhY0as/yLb2Y8m2mGNq+3KXZqMz3Ut/bHP0p\nRxq11zjQ6De7HmjUXqRRPemYpmOF7ttQuVeirbdVOPfsqmxwiLlZ0qbFX5l/RdPd6r3r3K38RX18\nZ7oL5muKfgeH8r3oGDrQ6AexAWh0st6tpvZKBAfS6EdGJzMqtyoFh41AGw7BgbYv9+sbDsGB2rJu\ncKh7wUO/BQoOVI7as+42VJ3lgd0Uri+e6l+xSpoyF/UH31YyxpjBo+eZgxRO6Mco3BKS+vp2GqVy\njeVMNyrKrBDNRpvGgoywNPO9FFwZOcqOl5iyiybmYdDKLpOYGzPfl50+MXTV0QnaO0GbDxo9PVoI\n2iOglZ1Tza6P2nI6aNuBVpe3gHY5aNRm1GWm3iMdt8eDVnbFxZQdUDF0SUlXdrknlhLv9/NAWwxa\n2WkXQz22LtBOBG0EaN8FjbaBjgnqcefOIVcHt5L0ClzVDwZ2KxljjElwcDDGGJPg4GCMMSbBwcEY\nY0yCg4MxxpgEBwdjjDEJTb/nsNkJ1d/fe1G+zMZ5CV+qIvYA7UHQctZMssb+CzTi+6DtBRplvi0n\n3ovpAI0sqWTrI6vueNDIPkoWZbI7jgGN9hHZHcmCTeXomP4VaEeDlrNZS2w7JfvoPaDR9j1fUyNo\nG+g4+zlolKea7LG0DVRP0uhYGsq452CMMSbBwcEYY0yCg4MxxpgEBwdjjDEJDg7GGGMSHByMMcYk\nNJ+y++Tqr3e5JF9k0bK8RpkvCbJKXgdaLgrS8shCSRplc30HaDRAUd2srGSBpXK0fTS0FNlVyQ64\nE2iUWZYs0XWT5JPFl7Q3g3YLaHS81LVXkkWUxk+pm4kYfuq160njUJBtuG6b1dXWAW0o456DMcaY\nBAcHY4wxCQ4OxhhjEhwcjDHGJDg4GGOMSXBwMMaYwWULSZdJul9hCPGrJO0c6ZdKalPwiB61guu6\nStL6dQo2O/B1o9H9tmrl3GuyhV48Jb/AabAysm1eDdomoOUGhqdMrpTBcXfQFoBGlr8DQKP2Ijtg\nXZvdaNAoqyfVhbJXrg3aG0CjTLb/AdoFoNF+p+yxlAGXrLp/BI0sxXeBRh7100D7LWgXgnYMaGRv\nJmvwRqCdDtpXQdsCNDoXUPbfnDX4vkZDLS0tUt/zbItCIt6LJf2g+G6cwgl8evH5Rkmvk/Q7SSeK\n3eOvGO45GGPM4DFJIdv6D6LvZisEhp9LmidpN0kzJR2icOX/0Yrl/FghXt8k6QFJEyX9ROGa4eJo\nvg6FTPNtkuYX650r6VrxNZmDgzHGDCJjJc3IaEcrdIrOlPQuhRsle0n6UaGfIenwYrohaUOFGw6f\nlnSFpK9Leo3CsDfjovl62EnSd4o6PCvpSKpo829IG2OMQZZKeqGYbm9vr5qlUfVlxN4KyR7GS7qz\npJXvpl1Z/J8r6UmFXoeK/20KPZKYh6LvZhTzZHHPwRhjBoh1FJ59bqJscJinEADKHKZwK+mTks5T\nuP1zrKTrYXU9gwF2q+/jzG5VX/jH83Rl5nkZBwdjjBk8JksaJSkeeHmcpOcUgsbc4vM8SXtKOniw\nK9iDg4MxxgwuRyjkabxfIRh8VdITkiZImqVgCBwhaUmp3Bnqm7uzkZnOUZ4HyzRvZW08nVHOzpfa\n5ZtZ6Zz788XIt7UhaB2g5eyxNBA72ewIsr39O2ifAO1ToJGJ+UnQMntUEg9eT+1C1ktaH0F23M1A\nyx990vGgPQca2aUngEZXYeUbyzGUdXYuaMSHQfsTaL8E7Z0160LsC9oc0MhOTTbsulbrrsz3c6qt\nrEMG9xyMMcYkODgYY4xJcHAwxhiT4OBgjDEmwcHBGGNMgoODMcaYhH6kz8iYSO/NGwYbkF6VbGM0\noDxZWbtBy9nNyKJGdk6qf25dUngFMseVoFGmV7LjknWPLLekUTuTjZAssNRmdAVD5W4FjepJ204Z\ngylD7Piay6SB7ak96djtAI22fT5oVE9aJmXAvQO0t4N2BWiUbbgudE4ayrjnYIwxJsHBwRhjTIKD\ngzHGmAQHB2OMMQkODsYYYxIcHIwxxiQ0b2X9Z8astsuXskWmLzorq5FNjbKyTgeNMoLmLI917Zx1\nrZfrgZYbqFzi7JxUF9oGsnPSMgmyV1J2Vaon2SSXgfZ+0ChjK62P9u1rQSP7L/EsaLT/6FiicpTD\nuQM0sqTW/R29DrQbQKPt2wI0siKTdZ3aeijjnoMxxpgEBwdjjDEJDg7GGGMSHByMMcYkODgYY4xJ\ncHAwxpjBo0sh/+ZcSbMkfUbVY0xPljRK0vliI1wz/K1OoeatrO/NmNymXJotUtdG+TBodeyqUj77\nKg0Y3wEaQbbFx0CbAhrZe+nImQZa3cyyxNagPQLaDqBR1tLnQPsUaCNBOwG0c0H7M2jHgtYG2gOg\nrQ/at0E7BzSypJKtlo4lsm8/XXN9J4P2OdBuBo1+txNBmwpaBUsl7VVMj5F0qcKubI/maS2qs0zS\nPpJO6d8qEl5fp5B7DsYYs3JYKOljkk6MvpsiabakscX/PRRewTi0ovxUheuV2xQyqu8r6feS7pV0\nZjTfkuL/xKLMr4v5f0aV68d4DsYYYwaYhxTeuxyjECwmKfQUHpD0lMLQFadG818k6bsK7xE3FHoX\n+yp0lC9X6JU8U5Q/t5iOb/vsKWl3SU8o3G56vTK3ndxzMMaYAeJFhVtzz0tqb2+vu5gJCr2G8cX/\nmBPUN8FEz9hGc4u/BUU1HpS0bcWyb1W4S91QeObRlquEg4MxxgwQIxVGmxutpoPDDgqP+BZKOl7h\nYfXhkn6j8Bzii5J+CuV7Msh0q282mW5V3xmK5+nKzCPJwcEYY1YWYyR9T9IFxecfSjpE0vUKt4fu\nV7gF9JGVUTkHB2OMGTxa1Wtl/YukayR9JdIPVMgvuo2qDZMXKdx2KtNQPm9iIzNd9fllqvy1lQs/\nMyP8EpYwB7x2jUl57fQ/5DUaPJwsj2SdzUF2zp1Buw80suJSNtB9QCNb3wdBWwQaZVClej4JGlka\njwTtMtBocPcRoFH22E+D9h3QjgGN7NnUnpeDRtv3b6D9BTTKcvsm0K4GjX4rHTXXNxo0sm/TOYKu\nlA8D7brM9w80GmppaZGaP8+uUrjnYIwxJsHBwRhjTIKDgzHGmAQHB2OMMQkODsYYYxKaTp/xYOb7\nETDo7Glgh9kIHEm5p/8SuxvqjENM0ZGSs5Hrgdwn5JIhp8hBoO0OGvEiaDQubi6J4fKgcuvWXCYl\nZ9sYtFbQ9geN3EpXgXYqaBeCRscSOd92BO2PoFHiPTpeyDlFSSPJRUi/FXLakcuQXHhUF3La0TKH\nMu45GGOMSXBwMMYYk+DgYIwxJsHBwRhjTIKDgzHGmAQHB2OMMQlNW1lzFrctoMxM0PYEjSxslGiN\nrKw5extZBckSR4m/yLJJFljaNhpjufWovLYYstaRVZc0si3WtfFSgjnaD1WjmfRA44PTWN40Gjsd\n7zuBdhNoZIUcBdoLoNExSJZUyhBHiQVvAY1+l6TtC9odoNF41nWpO9b1UMY9B2OMMQkODsYYYxIc\nHIwxxiQ4OBhjjElwcDDGGJPg4GCMMSahaStrzspF0eXjoE0Ejaxhk0GrY0sl2xttG2VpJMsm1ZEg\nKx35XKmeC0Cj7JzPgUaZUMmquytoNC51N2gElaubKfRR0GA4dcyu+jHQaDz1+aBRRlOyBm8HGh3X\nZKul39940OjEdSdoBO3bupmIhzLuORhjjElwcDDGGJPg4GCMMSbBwcEYY0yCg4MxxpgEBwdjjDEJ\nTVtZc1ZQynz5Hgo94Hl89T/z2nRYJJGrP2UYJagcZRElaynZQDtAu+5sEAHKBkrbsAy0zWuubx/Q\nbqy5PsqgStlxHwdtd9DGgjYNNKrnJND+BNrDoG0F2ith56RjibL/kqX4BtAo6yydr8iiTfZ6sikP\nZdxzMMYYk+DgYIwxJsHBwRhjTIKDgzHGmAQHB2OMMQkODsYYYxKatrLmsi6SNVNvBW3LvLTHj/Ia\nDbhOmTZz9SRL4wagkc2OMpoSj4B2DWiU0XQ0aLTtlEF1R9DI8keDydO+o3K0DWS9hES2agftSNDo\nmCBr6ROgXQ8aZdVtA432EZ0Q6BgkCyydBsimfDtoHaDRMU/nKypHlmmyBg9l3HMwxhiT4OBgjDEm\nwcHBGGNMgoODMcaYBAcHY4wxCQ4OxhhjEpq2suYsYNtQoZ1BAysrDbhOtkayouWyqNbNNEl2QLJl\nUlZPGtz9DtCmgEb1RBsyQNY9Wh/ZHe8BjTLgkn2UsoGSbfg00HKWbkkaD9qToNF+eBo0yj5Kbb0U\nNNq3D4JGV5lzQCPItk6/W/r9UcZdyhpM5x3at0MZ9xyMMcYkODgYY4xJcHAwxhiT4OBgjDEmwcHB\nGGNMgoODMcaYhKatrDmL25gWKLQTaOBdJAsbWcqInB2SBhVfBhrZD8kSdxdo94FGg9C3gUbWRGpL\nstWSNZEslGQDfQw0ygLbAdr9oFE9KdMr7aNnQHs9aJSZ9G7QyLI5FjTKNjwXNNrvZI8l+yjth1tA\nI0s4WbtpfXSlTBlwyW5cQZek2ZJaiukTJd3Uv0W8zN6SjpH0nzXLI00HB2OMMSvMUkl7FdOHSPqa\npIk1lzWj+HtF8G0lY4xZOWygfMdjiaSvK3Tm/iJpf0nTJD0g6fBinomSriym2yX9SKHj9ICkk1a0\ncg4OxhgzeLRKmilpvqSLJJ0VaTOj6XUUxnoaq3A37CuSDpJ0RDFdxS4KvZH9JJ0uvpO7XHxbyRhj\nBohl6n1W2d7eXjXLC+q9rbS/pEvU+4hor2i+FyVdW0zPUcgU06XQk2irWG5D0lUKjxKfkvQPhQHs\n6JEP4p6DMcYMEKMkrV/8ZYJDzM2SNi3+ysR+kW71ptLqVv6iPk631QXzNYWDgzHGrBx2U7j189QA\nLIt8o7VoOrJccGr197ueky9zExisFjXyGmXTpESv00DLWVnJkkqWWsoGujFoH6q5zOdB+ytoZN2j\nbSfr7J2g0U3Ourba/UCjjJjUZpTp9eGa5Y4CjY6lq0Gj/UeW6T1B2w40yrxKVlbaf1RPahc6Pum3\nQvuIrobp2KUsvm8FrYKeZw5SOKEfo3BLSMX3PbeWymfIxnKmGxVlVgg/czDGmMGDzrnxM4f1o+kz\nSvP1aFOLv6p59uhvxcr4tpIxxpgEBwdjjDEJDg7GGGMSHByMMcYkODgYY4xJaN6tlHn2vT0UuQ+M\nVWRTI1vcA6BtDlrOEjimRpnlaaNBI5suWQVpQHVIcIvtTMskGygtkwzblL1yB9A2BI2grKW0Hyhr\nKVlnLwHtSNBoP1C2U7JsUjZXyry6CDSCrKV1f+t0vFDWYLLO0nFN++FF0IYr7jkYY4xJcHAwxhiT\n4OBgjDEmwcHBGGNMgoODMcaYBAcHY4wxCU1bWVsyKTWPgzJngkbWMLLTfRA0GqV7ZOb7urbTXUGj\n+pPtlDKhkjWRrIJkuSXrHmUmpXahbF+07TNBOxo02gbiWdBodBSySa4L2l6gXQsa2XHJPvoH0N4N\nGh1nnwDtQtDIPkrbQDZeyqBa1467sOYy9625vlUd9xyMMcYkODgYY4xJcHAwxhiT4OBgjDEmwcHB\nGGNMgoODMcaYhJYm52s0uidWK6dMzRbqOje/wINhZduAtgA0GgQ8l/2R7GuUsZWsuKR9GbSNQaOM\nrdQmHaCRXZUyk5KNkGyuZMukq5RNQCOb5NagUXZfsrK2gfZm0Gj/3QXa7qDdDhq19XdAOwe0a0A7\nCDTKZEtQe74TtM+CtiNo94FG2WNzv9u7Gw21tLRI6Xl2C0nnS9pHwVW9QNLJURUulfQFBdfxk5Iu\ng9Uvj6sU3gB4rr8F3XMwxpjBo0XS7yVNlrSTQoD4vPqOONCmcF13oKQbVnB9b1eNwCA5OBhjzGAy\nSeHmwg+i72ZLmi7p55LmSdpN4b3QQxSu/D9asZwfK7x7eJNCR3iipJ8odEQvjubrUOjctEmaX6x3\nrsK7l/gOqYODMcYMHmMlzchoR0s6XSG5xLskXa3wcv2PCv0MSYcX0w2FcbAOkPRpSVdI+rqk1ygk\nKhgXzdfDTgp3Fccq3M6iMaj6MRKcMcYYZKl60360t7dXzQLjY0qS9pZ0naTxku4saaeXPl9Z/J+r\n8GxiXvF5nkJPYXZp/oei72aIH6G552CMMQPFOpI2Lf4ywWGeQgAoc5jCraRPSjpP4fbPsZKuh9X1\neF+6JS2Lvu9W9YV/PE9XZp6XcXAwxpjBY7KkUZJOiL4bp/DQeG+FXsA4hSCyp9jY+YrS/G2lnaZW\nf39Evsga4M1cD0YPJwvpdqDR4PbLMt+/A8qQzZWySZKl9jegkQWWMlQSZC0laNvpKRZluSVLI1kv\nc/tO4iypZA0mKyttHx1jlAn186CdDxq1C207HS+PgkbHy3zQ6PdAWYPJFk0WG8r+S3bVzUEbBRrZ\nvsnmmuEIhd1+qkLTPaRgZZ0gaZakEcXfklK5MyTdJumPxef4FtXybldVzYNl/MzBGGMGlyckfSCj\n9by+8qYKLX7mcGw03aHeB9Blbfvi/9Oleb61vEr6tpIxxpgEBwdjjDEJDg7GGGMSHByMMcYkODgY\nY4xJaN6tdFzm+9O+lC3y/LfOympk9yQrIThnkVz2qvIriDE0CD1lA30JtA+DdgBoU0CjtqRtADex\nFoNG1j3ad2TLJBsh2SR3AI0slCNB2xC0ETXX91vQCLIUk12VrvoeBI28jfeDRvudfitkZaVj4veg\n0X4gSypB27dFzWWu6rjnYIwxJsHBwRhjTIKDgzHGmAQHB2OMMQkODsYYYxIcHIwxxiQ0b2X9wh3V\n3zc2zRb5hfJWVrJDUnZSyuzZClrOTkdZWakeZBGdCRpZZ28DjTKTkt2RMluSjbBulk262qBytD6y\nj94O2ragEZQVmAahp4y0Y0G7B7S61tndQSPomKB9S79nqucC0Og3Rvv9rpp1Ifs2laNjYijjnoMx\nxpgEBwdjjDEJDg7GGGMSHByMMcYkODgYY4xJcHAwxhiT0LyV9ey9q7+/IF+krSWvzfm/vPbWj+a1\nrfOS7gZt/cz3v4QyZOsj2xvZD2nQe7IDUrmjQLsMNMrmStu+CDTK9EqQ9bKuffRG0Gj/HQwaZTTd\nCrRHQaMrNLJuUwZV2oYLQaPso3uBRrbvDUAjyFJM0DY8BRrZxd8G2hVcnTJdkmYrnCZeknSJpPOU\n7s7Jkg6VdI6kX0i6pX+r6cPfJL2+v4XcczDGmMFjqUKcHSvpLQoB4PTSPK0KGe6XSdpH0owVXGe/\nA4Pk4GCMMSuLhZI+JunE6LspCj2LscX/PRTejz20ovxUSecW+nxJ+yoMdXGvpDOj+ZYU/ycWZX5d\nzP8zqlzzt5WMMcYMNA8p3MUdoxAsJkk6RdIDCnfB3i7p1Gj+iyR9V9IdCreilikEhU9JulyhV/JM\nUf7cYjq+ZbWnwl3cJ9R7u+lvVRVzz8EYYwaIToVncosktbe3113MBIVew/jif8wJCoGhh55HHnOL\nvwUKj4AeVHUGmVslPa4QMGZJastVwsHBGGMGiLUVHsBvoKaDww4KD6kXSjpeITXb4ZJ+I6ld0hcl\n/RTK9zxH71bfZ+rdqr4zFM/TlZlHkoODMcasLMZI+p56PZ8/lHSIpOsVbg/dr3AL6CMro3LNP3PY\nMmOcAz/dYtC6j8trlE2TsowSOXvpB6AMWfcoY+SfQaMMnGQHpEHMKWMk1ZOyuZIdkK4oaDD5uhbf\nbtBo++pmNB0JGkG20w1Bo7ambad61v0NkZ36XtAoqy7RBRptA1mK6XdE7UnHC207LbOCVoXeQdnK\n2sOBkqZL2kZSR0X5+JlDTEP5s3EjM131+WX8QNoYYwaP5Z1zfxtNV127nhBNT4qmpxV/VVrPa15T\ni78eTqKK+LaSMcaYBAcHY4wxCQ4OxhhjEhwcjDHGJDg4GGOMSWjerZTzqoF38d2wuG+AzXUHKEeW\nQLL2PZ75fhaUoTSINDA6ZaEkqycxHrSdQaPso8Qo0KidaX1k+SMrJNkd1wGNMsuSZXNL0OruP7K5\nUj0JyspKb03Rtr8EGtmGiaU163IbaHSOIOhqmCzFlDWYskEPZdxzMMYYk+DgYIwxJsHBwRhjTIKD\ngzHGmAQHB2OMMQkODsYYYxKat7LmUiSC/2uNo/Pa676f1+ZANcgWRzbKnPYeKDMOtLtAo/pfBhqx\nBDSyuVK2UxpsnaArCrJlUtZLsseSlZUGhSdo228FjeyOo0Ej62VdG2/Onr28ZZKleH3QJoF2Hmhk\nNyZr+htBmwwabTttH1l1yXJb14q8quOegzHGmAQHB2OMMQkODsYYYxIcHIwxxiQ4OBhjjElwcDDG\nGJPQvJU1l76UvITvzUtv+HVem/x0XmuD1VE21O0y318HZX4M2qagLQStrsXwUdCmgEZ2R7LnkUZs\nBRrZMsnqeSNom4PWBhq19UXguT0QGoZsrtSe80D7OGgXgEa2YboipGy800Eji/kmoBEdoOV+z5IE\np4/aV8PUnnV/K6s67jkYY4xJcHAwxhiT4OBgjDEmwcHBGGNMgoODMcaYBAcHY4wxCc1bWXfMfE8+\ntVwmV0kt6+W10eBFIzvkAtByi3w/lKGsrJRF9K+gfRo0yup5D2g/AI0seLQ+stySdW8MaHUzqBJU\nz+dBI9vz5bCBZA2ua8elcmRhpmynD4JG++850CgTcV1o/5FGtlo65imDKpySsC5kYR7KuOdgjDEm\nwcHBGGNMgoODMcaYBAcHY4wxCQ4OxhhjEhwcjDHGJDRvZf175nsawX6XvNiA3ImUKXUCaJShM+eq\nvRbK/Ba0BmhkdyQrHVkvF4NGGSpvq7k+2q00SPsi0MgOeAtoZF8myLJJtlravrGgUTZQcnyTth9o\nj4BGNmWy1T4FGrUn2UfJHkvHWRtoZNWlbaeMyWRlfRI0Ou8MZdxzMMYYk+DgYIwxJsHBwRhjTIKD\ngzHGmAQHB2OMMQkODsYYYxKat7LmUkCSN1NLsspjD+dLPQtLfAw0skrmLHpvgjKkbQra7aCdBhpl\nNCWb3TtAuwI0SJqL9lHKBkpXG6TVtRh2g0ZW3XVBuxs0qidl56S2Jpvyr0CbCxpZRMl6SdtAVl06\nDWwIGmVSpsy5u4IGpxaEjhfKwkznnaGMew7GGGMSHByMMcYk9Ds4TL0PNHgVcurU/A2Am2B99Hbl\nfNBocBx6s5SWSfW8AbSZoNEbxf8Ejbrjs0B7AbSlNTXaR/kbi7xMqid146kc3b6hW5n3gpbbf89A\nmX+AVnefUztTXehWEe3XJ0Cj2zNUFypHb0RTu9B+pfVRe9L+o2NsqDGwwQFaZlUKDjS6Fi3zZtBo\n9Dc6WdP21T1R3Ala3eBQ96RLP0BaJmmU+oLK0Q+egjQc8tn9Ryclem5B6SvqBgeqS93gQOkkaJ/X\nPVk/BBq1C+1XWh9ptP9oPww1fFvJGGNMQvNupZFFOrI1O6WRkachznI1olMaHfsd4mf8z/eZuWX9\nF3ulzk61rN1bru8iOzU60uIEX2t2dmpEpHWBFtdqrc5OrV1o5YRhcbmWklauZ1lToZWdGy2dnVqz\n0MpJweLtK7uARnR2ap1Cay1pa3V2qjWzvjWi9ZVdOUs6O7VuZtufi7SyW2lxpJW3YWS0DeUD6pmo\nXFmLl1nuV8b1LCd86+zs1HqZbYjLlbd9ZKSV2zrehrIzZc3OTo1sYv+tnfle6rv/RkT7Tup7hRbv\n83K5tUrl4u2Lt61cz3Jd1ipp8fpeanIbqC7P9qMuVG5UpK3Z2alRTdYlXt/I0vqis06yvng/PFPS\naP/RfhjKJOe/DFPFzk5jjDEp0yRNXNmVMMYYY4wxxhhjjDHGGGOMWRXZWdIbKr5/g6Qdm1zGGFWn\nDDq0n3V5VRPzVC3z3ZJOjD7fqmCZfkjS+/pZh7psqvDg3+05MKxq7em2DPjY7G3PYc9VksZVfD9O\n0pXF9EcUwGqSAAAETElEQVQr9BZJ7QrvcD1T/P1T0umSXqvgpItfGv5p8f9z0XflnRm/c1Me2pmW\neaP6HmyzFIbsfZWkycV3/Tl43yjpf4vpqm0/QMHZ9TuF4a7nFnVfqHCwuj37Mhzac6aks4tpt6WP\nzYX9XM+QhJKLPiJpK/XdSdcX/z8j6S+Sto+0HST9WcHWNV3hxcVzJB0t6a5innhZ5YwTS0E7H5ZZ\n3obvRNNzlT/QYiZI+oZCssepki5WfttnSDpE4YB/VtL+xfe7iV9AdnsO3facGX12W/rY3E2cFGFY\ncD9oCxUi5hKFrMJfLOZfV6FhqrqXY9Sb2WG2pAMlnaSQMeAW9U270p8DpuddmaplLi9jQu5A21Xh\nimi+QtqkkyT9vdBOFm97D+VMHJT1we05dNuTgoPbcvU8Nimd2rDgMkkfq/j+BPV2NWcqdNsOV8jF\ndZ2Wn8/qOoXu1xEK9zN7GjJOT19u3IZCCp/FCi9xLi59zi3z95lt+ISkXxbTVQdaQ2EohLib2pPe\npS2qY3nb4zRD5W14JlMXt2dvHYdie3YVf27LvqzOx+awCA6UPuNkhQY/WqELJUl7K0TvxxXu8W0n\n6UiFRl8o6c3ihrlPoYFnK+zY90naSdIfJO2u3gZvVd/G7xKP+dKaWeYsScdK+pCkO4p5JyhkOug5\n0DZTuDd5tcK9xddKOk6hy3iDpGsk/Vq9D5rOVjhoqra95yRRtQ2tRV3cnsOrPZcWn3Pt6bZcPY/N\nYU+LpIMkfUoh2h5U0udJeq+kryncd5uukCZnceavJ3XLlGgZMxW6oUeuYF1zy2yRdHBmG1oVDuJT\nJF1a1PEPxWcpdB+PlvRHhauk7yocSFL1tsf3Oatwe66e7em2TLd9RRgK7bna8/NoeqZC7qp9+rmM\n4weuOi9zXD/mbfbg3Vih29rjfKja9r37sd4q3J695YZre7otB5ah2p7Dlipf9GEaGF90f2nGF90s\n/TnQYg5TsL5dWLO827Mvw6U93ZYBH5urEc28A1EF+aLrvjwS3/cs+6KJgXhppmx9O6kf649xewaG\nW3u6LX1srnbQOxBzQSNf9Gdq1oU800QzL81UQda3urg9h2d7ui19bK520DsQpJEvuu6LI3UPGHpp\n5hYo16289a0ubs/h2Z5uy5TV/dgcMtQdJvR25X3RMyq+72EtVQ/BulD9GZWuL+PU65DYQ30dEzQM\n7kalz3G3k+6PvkdhqOIbJH1PwR2xovlU3J7Dsz3dlimr+7E57NlC0k0Kr8ifW/xNk3SzpC2hHEX7\nwX5x5FLlX5r5RRPlyfrWX9yebs8Yt+XAsiq155BhRaJgi6RJksYqvGU4T3z/TgovjuTyuLSq/hVF\nHTZX8DkvU/rSzLvVNwHY8thYwQd9lFJ/eLO4PXtZ3dvTbTmwrGrtOSRY3btIPS/+vEbNH/Qmj9tz\n4HBbDixuT2OMMcYYY4wxxhhjjDHGGGOMMWZV4P8BItJuzALOqagAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f078b399650>"
       ]
      }
     ],
     "prompt_number": 324
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "A simple softmax"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "As an initial baseline, we'll train a simple softmax model. First we need to flatten the data to a single pitchgram and a sparse chord matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# small_data = data[:20]\n",
      "small_data = data\n",
      "\n",
      "flat_len = sum(len(p) for p, c in small_data)\n",
      "flat_pg = np.zeros((flat_len, small_data[0][0].shape[1]), dtype=floatX)\n",
      "flat_chords = np.zeros(flat_len, dtype='int32')\n",
      "i = 0\n",
      "for p, c in small_data:\n",
      "    flat_pg[i:i + len(p)] = p\n",
      "    flat_chords[i: i + len(p)] = c\n",
      "    i += len(p)\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 492
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LEARNING_RATE = 0.01\n",
      "N_EPOCHS = 100\n",
      "BATCH_SIZE = 2000"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(object):\n",
      "\n",
      "    def __init__(self, input, n_in, n_out):\n",
      "        self.W = theano.shared(np.zeros((n_in, n_out), dtype=floatX), name='W', borrow=True)\n",
      "        self.b = theano.shared(np.zeros((n_out,), dtype=floatX), name='b', borrow=True)\n",
      "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
      "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "    def negative_log_likelihood(self, y):\n",
      "        return T.mean(T.nnet.categorical_crossentropy(self.p_y_given_x, y))\n",
      "\n",
      "    def errors(self, y):\n",
      "        return T.mean(T.neq(\n",
      "            T.argmax(self.p_y_given_x, axis=1),\n",
      "            T.argmax(y, axis=1)\n",
      "        ))"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class HiddenLayer(object):\n",
      "\n",
      "    def __init__(self, rng, input, n_in, n_out):\n",
      "        rand_max = np.sqrt(6. / (n_in + n_out))\n",
      "        self.W = theano.shared(rng.uniform(-rand_max, rand_max, (n_in, n_out)).astype(floatX),\n",
      "                               name='W', borrow=True)\n",
      "        self.b = theano.shared(np.zeros((n_out,), dtype=floatX), name='b', borrow=True)\n",
      "        self.output = T.tanh(T.dot(input, self.W) + self.b)\n",
      "        self.params = [self.W, self.b]"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ConvLayer(object):\n",
      "\n",
      "    def __init__(self, rng, input, image_size, filter_size, num_filters,\n",
      "                 num_input_filters, pool_size, batch_size):\n",
      "        self.input = input\n",
      "        self.image_size = image_size\n",
      "        self.filter_size = filter_size\n",
      "        self.num_filters = num_filters\n",
      "        self.num_input_filters = num_input_filters\n",
      "        self.pool_size = pool_size\n",
      "        self.batch_size = batch_size\n",
      "        self.output_size = get_conv_output_size(image_size, filter_size, pool_size)\n",
      "\n",
      "        fan_in = np.prod(filter_size)\n",
      "        fan_out = (fan_in * num_filters) / np.prod(pool_size)\n",
      "        rand_max = np.sqrt(6. / (fan_in + fan_out))\n",
      "        image_shape = (batch_size, num_input_filters) + image_size\n",
      "        filter_shape = (num_filters, num_input_filters) + filter_size\n",
      "        conv_input = input.reshape(image_shape)\n",
      "\n",
      "        self.W = theano.shared(rng.uniform(-rand_max, rand_max, size=filter_shape).astype(floatX),\n",
      "                               borrow=True)\n",
      "        self.b = theano.shared(np.zeros((num_filters,), dtype=floatX), borrow=True)\n",
      "\n",
      "        conv_output = conv.conv2d(input=conv_input,\n",
      "                                  filters=self.W,\n",
      "                                  filter_shape=filter_shape,\n",
      "                                  image_shape=image_shape)\n",
      "        pooled_output = downsample.max_pool_2d(\n",
      "            input=conv_output,\n",
      "            ds=pool_size,\n",
      "            ignore_border=True)\n",
      "\n",
      "        self.output = T.tanh(pooled_output + self.b.dimshuffle('x', 0, 'x', 'x')).flatten(2)\n",
      "        self.params = [self.W, self.b]"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_size_1 = (84, 16)\n",
      "filter_size_1 = (12, 8)\n",
      "pool_size_1 = (1, 1)\n",
      "output_size_1 = get_conv_output_size(image_size_1, filter_size_1, pool_size_1)\n",
      "num_filters_1 = 10\n",
      "print output_size_1"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(73, 9)\n"
       ]
      }
     ],
     "prompt_number": 530
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_size_2 = output_size_1\n",
      "filter_size_2 = (8, 8)\n",
      "#filter_size_2 = (8, 8)\n",
      "pool_size_2 = (1, 1)\n",
      "output_size_2 = get_conv_output_size(image_size_2, filter_size_2, pool_size_2)\n",
      "num_filters_2 = 10\n",
      "print output_size_2"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(66, 2)\n"
       ]
      }
     ],
     "prompt_number": 532
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_size_3 = output_size_2\n",
      "filter_size_3 = (6, 2)\n",
      "pool_size_3 = (1, 1)\n",
      "output_size_3 = get_conv_output_size(image_size_3, filter_size_3, pool_size_3)\n",
      "num_filters_3 = 20\n",
      "print output_size_3"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(61, 1)\n"
       ]
      }
     ],
     "prompt_number": 524
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Network(object):\n",
      "    def __init__(self, input, n_out):\n",
      "        N_LAYERS = 2\n",
      "\n",
      "        n_hidden = 500\n",
      "        rng = np.random.RandomState(1)\n",
      "\n",
      "        self.conv_layer_1 = ConvLayer(\n",
      "            rng=rng,\n",
      "            input=input,\n",
      "            image_size=image_size_1,\n",
      "            filter_size=filter_size_1,\n",
      "            num_filters=num_filters_1,\n",
      "            num_input_filters=1,\n",
      "            pool_size=pool_size_1,\n",
      "            batch_size=BATCH_SIZE\n",
      "        )\n",
      "        self.conv_layer_2 = ConvLayer(\n",
      "            rng=rng,\n",
      "            input=self.conv_layer_1.output,\n",
      "            image_size=image_size_2,\n",
      "            filter_size=filter_size_2,\n",
      "            num_filters=num_filters_2,\n",
      "            num_input_filters=num_filters_1,\n",
      "            pool_size=pool_size_2,\n",
      "            batch_size=BATCH_SIZE\n",
      "        )\n",
      "        self.conv_layer_3 = ConvLayer(\n",
      "            rng=rng,\n",
      "            input=self.conv_layer_2.output,\n",
      "            image_size=image_size_3,\n",
      "            filter_size=filter_size_3,\n",
      "            num_filters=num_filters_3,\n",
      "            num_input_filters=num_filters_2,\n",
      "            pool_size=pool_size_3,\n",
      "            batch_size=BATCH_SIZE\n",
      "        )\n",
      "\n",
      "        self.conv_layers = [self.conv_layer_1, self.conv_layer_2, self.conv_layer_3]\n",
      "        final_conv = self.conv_layers[-1]\n",
      "\n",
      "        self.hidden_layer = HiddenLayer(rng, final_conv.output, np.prod(final_conv.output_size) * final_conv.num_filters, n_hidden)\n",
      "        self.output_layer = LogisticRegression(self.hidden_layer.output, n_hidden, n_out)\n",
      "        self.params = [p for l in self.conv_layers for p in l.params] + self.hidden_layer.params + self.output_layer.params\n",
      "\n",
      "    def negative_log_likelihood(self, y):\n",
      "        return self.output_layer.negative_log_likelihood(y)\n",
      "\n",
      "    def errors(self, y):\n",
      "        return self.output_layer.errors(y)\n",
      "\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_conv_output_size(image_size, filter_size, pool_size):\n",
      "    output_size = (np.array(image_size) - np.array(filter_size) + 1.0) / pool_size\n",
      "    assert output_size[0].is_integer()\n",
      "    assert output_size[1].is_integer()\n",
      "    return tuple(output_size.astype(int))\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_width, patch_height = image_size_1\n",
      "pg_patches = np.zeros((flat_len, patch_width * patch_height), dtype=floatX)\n",
      "\n",
      "before = int(patch_height * 0.5)\n",
      "after = patch_height - before\n",
      "for i in xrange(len(flat_pg)):\n",
      "    i_before = i - before\n",
      "    i_after = i + after\n",
      "    pad_before = np.zeros((- min(i_before, 0) * patch_width))\n",
      "    pad_after = np.zeros((- min(len(flat_pg) - i_after, 0) * patch_width))\n",
      "    pg_patch = flat_pg[max(i_before, 0):min(i_after, len(flat_pg))].flatten()\n",
      "    pg_patches[i] = np.hstack((pad_before, pg_patch, pad_after))\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 493
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def as_theano_shared(x):\n",
      "    return theano.shared(x, borrow=True)\n",
      "def split_train_test_theano(data, classes, train_test_ratio, cast_classes_to_int):\n",
      "    if cast_classes_to_int:\n",
      "        cast = lambda x: T.cast(x, 'int32')\n",
      "    else:\n",
      "        cast = lambda x: x\n",
      "    assert len(data) == len(classes)\n",
      "    split_i = int(len(data) * train_test_ratio)\n",
      "    return (as_theano_shared(data[split_i:]),\n",
      "            cast(as_theano_shared(classes[split_i:])),\n",
      "            as_theano_shared(data[:split_i]),\n",
      "            cast(as_theano_shared(classes[:split_i])))"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data, train_classes, test_data, test_classes = split_train_test_theano(pg_patches, flat_chords, 0.5)"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "split_train_test_theano() takes exactly 4 arguments (3 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-693-311dcbc06304>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             cast(as_theano_shared(classes[:split_i])))\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_train_test_theano\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpg_patches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_chords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: split_train_test_theano() takes exactly 4 arguments (3 given)"
       ]
      }
     ],
     "prompt_number": 693
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train_batches = train_data.get_value(borrow=True).shape[0] / BATCH_SIZE\n",
      "n_test_batches = test_data.get_value(borrow=True).shape[0] / BATCH_SIZE"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 500
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = T.lscalar()\n",
      "x = T.matrix('x')\n",
      "y = T.ivector('y')\n",
      "\n",
      "clf = Network(input=x, n_out=np.max(flat_chords) + 1)\n",
      "cost = clf.negative_log_likelihood(y)\n",
      "\n",
      "grads = [T.grad(cost, wrt=p) for p in clf.params]\n",
      "updates = [(p, p - LEARNING_RATE * g) for p, g in zip(clf.params, grads)]\n",
      "\n",
      "train_model = theano.function(\n",
      "    inputs=[index],\n",
      "    updates=updates,\n",
      "    outputs=cost,\n",
      "    givens={\n",
      "        x: train_data[index * BATCH_SIZE:(index + 1) * BATCH_SIZE],\n",
      "        y: train_classes[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
      "    })\n",
      "\n",
      "test_model = theano.function(\n",
      "    inputs=[index],\n",
      "    outputs=clf.errors(y),\n",
      "    givens={\n",
      "        x: test_data[index * BATCH_SIZE:(index + 1) * BATCH_SIZE],\n",
      "        y: test_classes[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
      "    })"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 534
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for epoch in range(N_EPOCHS):\n",
      "    for minibatch_index in range(n_train_batches):\n",
      "        train_model(minibatch_index)\n",
      "    test_error = np.mean([test_model(i) for i in range(n_test_batches)])\n",
      "    print 'epoch %d; test error: %f' % (\n",
      "        epoch, test_error)            "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch 0; test error: 0.721570\n",
        "epoch 1; test error: 0.693535"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2; test error: 0.650860"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3; test error: 0.613826"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4; test error: 0.586424"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5; test error: 0.562483"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6; test error: 0.543500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7; test error: 0.527924"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8; test error: 0.515064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9; test error: 0.503465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10; test error: 0.493529"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11; test error: 0.484831"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12; test error: 0.477169"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13; test error: 0.470698"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14; test error: 0.465093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15; test error: 0.459448"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16; test error: 0.453878"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17; test error: 0.449262"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18; test error: 0.444936"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19; test error: 0.441041"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20; test error: 0.437430"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 21; test error: 0.433727"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 22; test error: 0.431390"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 23; test error: 0.427855"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 24; test error: 0.425448"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 25; test error: 0.423262"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 26; test error: 0.421320"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 27; test error: 0.419802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 28; test error: 0.417564"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 29; test error: 0.415831"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 30; test error: 0.413343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 31; test error: 0.411715"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 32; test error: 0.409529"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 33; test error: 0.408349"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CHORDS_BATCH_SIZE = 1000"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chord_patch_width = 128\n",
      "chords = [c for d, c in data if len(c) >= chord_patch_width]"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chord_stride = 4\n",
      "num_chord_vecs = int(sum(math.ceil((len(c) - chord_patch_width + 1) / float(chord_stride)) for c in chords))\n",
      "               \n",
      "num_chords = 24\n",
      "num_chords_input = num_chords + num_chords - 2 # C to B + C to Bb\n",
      "chords_input = np.zeros((num_chord_vecs, chord_patch_width, num_chords_input), dtype=floatX)\n",
      "chords_output = np.zeros((num_chord_vecs, chord_patch_width), dtype='int32')\n",
      "i = 0\n",
      "for a, c in enumerate(chords):\n",
      "    for j in range(0, len(c) - chord_patch_width + 1, chord_stride):\n",
      "        for k in range(chord_patch_width):\n",
      "            n =  c[j + k]\n",
      "            if n >= 24:\n",
      "                continue\n",
      "\n",
      "            chords_input[i, k, n] = 1\n",
      "            if n < 22:\n",
      "                chords_input[i, k, n + 24] = 1\n",
      "            chords_output[i, k] = n\n",
      "        i += 1\n",
      "\n",
      "chords_input = chords_input.reshape(num_chord_vecs, 1, chord_patch_width, num_chords_input)\n",
      "chords_output = chords_output.reshape(num_chord_vecs, chord_patch_width)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_input, train_output, test_input, test_output = split_train_test_theano(chords_input, chords_output, 0.5, True)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chord_train_batches = train_input.get_value(borrow=True).shape[0] / batch_size\n",
      "chord_test_batches = test_input.get_value(borrow=True).shape[0] / batch_size"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MultiOutputDenseLayer(lasagne.base.Layer):\n",
      "\n",
      "    def __init__(self, incoming, num_outputs, num_output_values,\n",
      "                 W=lasagne.init.Uniform(), b=lasagne.init.Constant(0.),\n",
      "                 nonlinearity=lasagne.nonlinearities.rectify, **kwargs):\n",
      "        super(MultiOutputDenseLayer, self).__init__(incoming, **kwargs)\n",
      "        self.num_outputs = num_outputs\n",
      "        self.num_output_values = num_output_values\n",
      "        num_units = self.num_outputs * self.num_output_values\n",
      "        self.W = self.create_param(W, (num_inputs, num_units), name='W')\n",
      "        self.b = self.create_param(b, (num_units,), name=\"b\") if b is not None else None\n",
      "\n",
      "    def get_params(self):\n",
      "        return [self.W] + self.get_bias_params()\n",
      "\n",
      "    def get_bias_params(self):\n",
      "        return [self.b] if self.b is not None else []\n",
      "\n",
      "    def get_output_shape_for(self, input_shape):\n",
      "        return (input_shape[0], self.num_outputs, self.num_output_values)\n",
      "\n",
      "    def get_output_for(self, input, *args, **kwargs):\n",
      "        if input.ndim > 2:\n",
      "            input = input.flatten(2)\n",
      "\n",
      "        \n",
      "                 "
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_layer = lasagne.layers.InputLayer(\n",
      "    shape=(CHORDS_BATCH_SIZE, 1, chord_patch_width, num_chords_input)\n",
      ")\n",
      "conv_layer = lasagne.layers.Conv2DLayer(\n",
      "    input_layer,\n",
      "    num_filters=50,\n",
      "    filter_size=(12, 12),\n",
      "    nonlinearity=lasagne.nonlinearities.tanh,\n",
      "    W=lasagne.init.Uniform(),\n",
      ")\n",
      "\n",
      "output_layer = lasagne.layers.DenseLayer(\n",
      "    conv_layer,\n",
      "    num_units=num_chords,\n",
      "    nonlinearity=lasagne.nonlinearities.softmax,\n",
      "    W=lasagne.init.Uniform(),\n",
      ")\n",
      "\n",
      "batch_size = 1000\n",
      "learning_rate = 0.1\n",
      "\n",
      "batch_index = T.lscalar('batch_index')\n",
      "index = T.lscalar()\n",
      "x_batch = T.tensor4('x')\n",
      "y_batch = T.ivector('y')\n",
      "batch_slice = slice(batch_index * batch_size, (batch_index + 1) * batch_size)\n",
      "\n",
      "objective = lasagne.objectives.Objective(output_layer, loss_function=lasagne.objectives.multinomial_nll)\n",
      "\n",
      "loss_train = objective.get_loss(x_batch, target=y_batch)\n",
      "loss_eval = objective.get_loss(x_batch, target=y_batch, deterministic=True)\n",
      "\n",
      "pred = T.argmax(output_layer.get_output(x_batch, deterministic=True), axis=1)\n",
      "accuracy = T.mean(T.eq(pred, y_batch))\n",
      "\n",
      "all_params = lasagne.layers.get_all_params(output_layer)\n",
      "updates = lasagne.updates.sgd(loss_train, all_params, learning_rate)\n",
      "\n",
      "train = theano.function(\n",
      "    [batch_index],\n",
      "    loss_train,\n",
      "    updates=updates,\n",
      "    givens={\n",
      "        x_batch: train_input[batch_slice],\n",
      "        y_batch: train_output[batch_slice],\n",
      "    }\n",
      ")\n"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "Cannot convert Type TensorType(int32, matrix) (of Variable Subtensor{int64:int64:}.0) into Type TensorType(int32, vector). You can try to manually convert Subtensor{int64:int64:}.0 into a TensorType(int32, vector).",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-48-28d52a59e2ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     givens={\n\u001b[0;32m     45\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_slice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0my_batch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_slice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     }\n\u001b[0;32m     48\u001b[0m )\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    488\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    491\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[0mcloned_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_v_get_shared_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mcloned_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcloned_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m#computed_list.append(cloned_v)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mclone_v_get_shared_updates\u001b[1;34m(v, copy_inputs_over)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mclone_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSharedVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mclone_a\u001b[1;34m(a, copy_inputs_over)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mclone_v_get_shared_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             clone_d[a] = a.clone_with_new_inputs([clone_d[i] for i in\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mclone_v_get_shared_updates\u001b[1;34m(v, copy_inputs_over)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mclone_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSharedVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mclone_a\u001b[1;34m(a, copy_inputs_over)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mclone_v_get_shared_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             clone_d[a] = a.clone_with_new_inputs([clone_d[i] for i in\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mclone_v_get_shared_updates\u001b[1;34m(v, copy_inputs_over)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mclone_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSharedVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mclone_a\u001b[1;34m(a, copy_inputs_over)\u001b[0m\n\u001b[0;32m    133\u001b[0m             clone_d[a] = a.clone_with_new_inputs([clone_d[i] for i in\n\u001b[0;32m    134\u001b[0m                                                   a.inputs],\n\u001b[1;32m--> 135\u001b[1;33m                                                  strict=rebuild_strict)\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mold_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_o\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mclone_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_o\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36mclone_with_new_inputs\u001b[1;34m(self, inputs, strict)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                     \u001b[1;31m# If compatible, casts new into curr.type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     \u001b[0mnew_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[0mremake_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter_variable\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[0mothertype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                     self=self)\n\u001b[0m\u001b[0;32m    206\u001b[0m                 )\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: Cannot convert Type TensorType(int32, matrix) (of Variable Subtensor{int64:int64:}.0) into Type TensorType(int32, vector). You can try to manually convert Subtensor{int64:int64:}.0 into a TensorType(int32, vector)."
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for epoch in range(N_EPOCHS):\n",
      "    for minibatch_index in range(chord_train_batches):\n",
      "        print minibatch_index\n",
      "        train_model(minibatch_index)\n",
      "    test_error = np.mean([test_model(i) for i in range(chord_test_batches)])\n",
      "    print 'epoch %d; test error: %f' % (\n",
      "        epoch, test_error)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "size must remain unchanged, changed from 11776000 to 5888000\nApply node that caused the error: GpuReshape{4}(GpuSubtensor{int64:int64:}.0, TensorConstant{[1000    1..  46  128]})\nInputs shapes: [(2000, 5888), (4,)]\nInputs strides: [(5888, 1), (8,)]\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(int64, vector)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-29-c47439f956c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mminibatch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchord_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mminibatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchord_test_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     print 'epoch %d; test error: %f' % (\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m                     \u001b[1;31m# For the CVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                     gof.vm.raise_with_op(self.fn.nodes[self.fn.position_of_error],\n\u001b[1;32m--> 588\u001b[1;33m                                          self.fn.thunks[self.fn.position_of_error])\n\u001b[0m\u001b[0;32m    589\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                     \u001b[1;31m# For the c linker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/basic_ops.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out_)\u001b[0m\n\u001b[0;32m   2221\u001b[0m                              \u001b[1;34m' has incorrect length %i'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2222\u001b[0m                              ', should be %i' % (len(shp), self.ndim), shp)\n\u001b[1;32m-> 2223\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: size must remain unchanged, changed from 11776000 to 5888000\nApply node that caused the error: GpuReshape{4}(GpuSubtensor{int64:int64:}.0, TensorConstant{[1000    1..  46  128]})\nInputs shapes: [(2000, 5888), (4,)]\nInputs strides: [(5888, 1), (8,)]\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(int64, vector)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node."
       ]
      }
     ],
     "prompt_number": 29
    }
   ]
  }
 ]
}